{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==============================================================================\n",
        "# EJERCICIO 3: ESTUDIO DETALLADO Y APLICACIÓN DE K-NN (K-Nearest Neighbors)\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"\n",
        "--- DOCUMENTACIÓN MEJORADA DEL ALGORITMO K-NN ---\n",
        "\n",
        "1. ¿QUÉ ES K-NN?\n",
        "   Es un algoritmo de aprendizaje supervisado \"perezoso\" (lazy learner).\n",
        "   - Perezoso: No \"aprende\" un modelo matemático complejo (como pesos o coeficientes)\n",
        "     durante el entrenamiento. Simplemente MEMORIZA todos los datos de entrenamiento.\n",
        "   - Predicción: Cuando llega un dato nuevo, busca en su memoria los datos más parecidos.\n",
        "\n",
        "2. PRINCIPIO DE FUNCIONAMIENTO:\n",
        "   \"Dime con quién andas y te diré quién eres\".\n",
        "   Para clasificar un punto nuevo 'P':\n",
        "   A. Calcula la distancia entre 'P' y todos los puntos de entrenamiento almacenados.\n",
        "      (Usualmente distancia Euclidiana: línea recta).\n",
        "   B. Selecciona los 'K' puntos más cercanos (los K vecinos).\n",
        "   C. Votación Mayoritaria: La clase más común entre esos K vecinos se asigna a 'P'.\n",
        "\n",
        "3. PARÁMETROS CRÍTICOS:\n",
        "\n",
        "   A. 'K' (Número de vecinos):\n",
        "      - K = 1: El modelo es muy sensible al ruido. Si el vecino más cercano es una anomalía, fallará.\n",
        "               Fronteras de decisión muy irregulares (Overfitting).\n",
        "      - K alto: El modelo se vuelve muy suave. Si K es demasiado grande, la clase mayoritaria\n",
        "                dominará siempre (Underfitting).\n",
        "      - K suele ser un número impar (3, 5, 7) para evitar empates en la votación binaria.\n",
        "\n",
        "   B. Métrica de Distancia:\n",
        "      - Euclidiana (estándar).\n",
        "      - Manhattan (suma de diferencias absolutas, útil en geometrías tipo cuadrícula).\n",
        "      - Minkowski (generalización).\n",
        "\n",
        "4. IMPORTANCIA DE LA ESCALA:\n",
        "   Al igual que SVM, K-NN depende totalmente de calcular distancias.\n",
        "   Es CRÍTICO normalizar los datos para que una variable con magnitud grande (ej: Salario)\n",
        "   no opaque a una pequeña (ej: Edad).\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================================================\n",
        "# APLICACIÓN PRÁCTICA: DIAGNÓSTICO MÉDICO (BREAST CANCER)\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Carga de Datos\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "# 0: Maligno, 1: Benigno\n",
        "\n",
        "print(f\"Dataset Cáncer: {X.shape[0]} pacientes, {X.shape[1]} características.\")\n",
        "\n",
        "# 2. Preprocesamiento (CRÍTICO EN K-NN)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 3. Búsqueda del mejor K (Aplicación de cambios para optimizar)\n",
        "# En lugar de elegir K al azar, iteramos para encontrar el K óptimo usando validación.\n",
        "\n",
        "k_values = range(1, 21)\n",
        "accuracies = []\n",
        "\n",
        "print(\"\\n--- Buscando el valor óptimo de K ---\")\n",
        "for k in k_values:\n",
        "    # Usamos cross_val_score para una evaluación más robusta en el set de entrenamiento\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "    accuracies.append(scores.mean())\n",
        "    print(f\"K={k}: Exactitud media = {scores.mean():.4f}\")\n",
        "\n",
        "# Graficar la curva de exactitud vs K\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(k_values, accuracies, marker='o', linestyle='dashed', color='blue')\n",
        "plt.title('Rendimiento de K-NN según número de vecinos (K)')\n",
        "plt.xlabel('Valor de K')\n",
        "plt.ylabel('Exactitud (Cross-Validation)')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Elegir el mejor K\n",
        "best_k = k_values[np.argmax(accuracies)]\n",
        "print(f\"\\nMejor K encontrado: {best_k}\")\n",
        "\n",
        "# 4. Entrenamiento y Evaluación Final con el mejor K\n",
        "final_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "final_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = final_knn.predict(X_test_scaled)\n",
        "\n",
        "print(f\"\\n--- RESULTADOS FINALES CON K={best_k} (Set de Prueba) ---\")\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"\\nExactitud en Prueba: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nCONCLUSIONES K-NN:\")\n",
        "print(\"1. K-NN es simple pero efectivo para este dataset médico.\")\n",
        "print(\"2. La gráfica muestra que un K muy bajo es inestable, y uno muy alto pierde precisión.\")\n",
        "print(\"3. La normalización de datos fue esencial para calcular distancias correctas.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ppenzkx2uMgN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}